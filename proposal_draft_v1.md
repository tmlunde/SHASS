# The Languages of Healing: What Clinical AI Cannot Hear

**A Proposal to the SHASS+ Connectivity Fund (Full Proposal)**

**PI:** Per Urlaub, Global Languages, SHASS
**Co-PI:** Leo Anthony Celi, Laboratory for Computational Physiology (IMES) / MIT Critical Data

---

## 1. What Goes Unheard

Science establishes truth through proof. This is its great strength — and its blind spot. What has not been proven is not thereby false. It may simply mean we have not yet looked, or that we have been looking with instruments too narrow to detect what is there. A grandmother in rural Uganda who detects malaria in her grandchild from the quality of the child's cry — hours before any biomarker confirms it — is not practicing folk belief. She is reading a communicative signal that no clinical AI system has been designed to hear. A community health worker in São Paulo who assesses a child through the timber of the mother's voice and the way the child shifts on her lap is processing diagnostic information that vanishes the moment it enters a medical record as text. A Sami noaidi who attends to the behavior of the reindeer herd and the rhythm of the wind before treating a patient is not performing ritual in opposition to medicine. They are attending to the relational field of health — something Western science is only now, through One Health and network medicine, beginning to formalize.

The fact that these communicative acts have not been systematically studied by clinical AI does not mean they lack clinical value. It means we built our systems without listening for them.

On January 15, 2026, we convened approximately 100 participants from diverse backgrounds — clinicians, linguists, AI researchers, ethicists, indigenous knowledge keepers, artists, students — at MIT, supported by the American Medical Association, to ask a question that clinical AI has not yet confronted: *what are the languages of healing, and how many of them can our systems actually hear?* The conversation that unfolded made clear that the answer is: almost none.

Clinical artificial intelligence is built on an extraordinarily narrow communicative foundation: typed English text in electronic health records. The global movement toward "multilingual clinical AI" seeks to expand this by adding more languages — a necessary effort. But it misses a more fundamental problem. Adding more languages to a text-based system is like adding more microphones inside a recording studio while the concert is happening outdoors. The problem is not which languages are represented. The problem is what we have decided counts as language at all.

The question this project poses is not *how do we make AI understand more languages?* but: **what if written text captures only a small fraction of the communicative acts through which healing actually occurs?**

Three converging lines of evidence make this question not speculative but urgent:

**Intelligence is not uniquely human.** A recent *Nature* commentary marshals evidence that artificial systems now display general intelligence, concluding that "for the first time in human history, we are no longer alone in the space of general intelligence" (Chen et al., *Nature* 650, 2026). If intelligence is substrate-independent — realizable in silicon as well as carbon — then the communicative signals relevant to health may also be medium-independent: carried not only in text, but in prosody, gesture, rhythm, ecological pattern, and interspecies behavior. The corollary is immediate: a clinical AI built only on text is not merely linguistically limited. It is *communicatively deaf*.

**Health is relational, not individual.** The One Health framework, social determinants of health, and network medicine demonstrate that human health is embedded in ecological, social, and environmental relationships. Indigenous healing traditions have always known this. Yet clinical AI models health as if it were a property of isolated bodies described in isolated texts — ignoring the relational field that both indigenous knowledge and contemporary systems biology recognize as foundational.

**Language encompasses far more than text.** An estimated 40% of the world's languages have no writing system. For the communities that speak them, health knowledge is transmitted through oral narrative, song, rhythm, environmental reading, and embodied practice — communicative forms that clinical AI has no mechanism to receive. Biosemiotics, ethnolinguistics, and multimodal discourse analysis have long recognized this expanded communicative universe. But clinical AI has not.

Taken together, these insights reveal that clinical AI suffers not from a language *translation* problem but from a language *truncation* problem. We have built systems that hear one frequency of a vast communicative spectrum and mistake that frequency for the whole.

This project develops the theoretical foundations and initial empirical evidence for an **expanded semiotics of health**: a framework for understanding the full range of communicative acts relevant to healing — across cultures, modalities, and ways of knowing — and for articulating what clinical AI must become if it is to truly listen.

---

## 2. The Textual Presumption and Its Costs

Our starting point is the well-established literature on linguistic justice in healthcare. Language barriers cause misdiagnosis, reduce treatment adherence, and exacerbate health inequities worldwide. The current response — in both clinical practice and AI — is translation: build systems in more languages, train interpreters, develop multilingual NLP.

We argue this response, while essential, rests on an unexamined assumption: that the relevant unit of clinical communication is the *word* — spoken or written, in whatever language. We call this the **textual presumption** in clinical AI.

The textual presumption has deep historical roots. Western medicine's epistemological revolution in the 19th century was, in significant part, a *documentary* revolution: the case history, the medical record, the pathology report. The electronic health record is the apotheosis of this tradition — the belief that if it is not written, it is not clinically real. Clinical AI inherits this belief without question.

But across most of human history, and in most of the world's healing traditions today, the clinical encounter is not primarily textual. It is:

**Prosodic and paralinguistic.** Research in clinical linguistics demonstrates that *how* something is said — tone, rhythm, pace, silence — carries diagnostic and therapeutic information that text strips away. A patient's hesitation before answering "I'm fine" may be the most clinically significant moment in an encounter. Clinical AI cannot hear it.

**Somatic and gestural.** The body communicates in clinical encounters through posture, movement, facial micro-expression. These are semiotic acts with formal structure. Traditional healing systems worldwide attend to them explicitly; Western clinical education once did too, before documentation eclipsed observation.

**Musical and rhythmic.** From the Sami joik to the icaros of Amazonian curanderismo to the growing neuroscience evidence for music therapy and rhythmic entrainment, melody and rhythm function as communicative modalities in healing that are irreducible to text. They operate on the body through pathways that clinical language does not.

**Environmental and ecological.** Indigenous healing traditions attend to environmental signals — seasonal patterns, animal behavior, weather, plant cycles — as integral to clinical reasoning. This is not mysticism. The One Health paradigm, now mainstream in epidemiology, validates precisely this insight: zoonotic disease surveillance already treats animal behavior as an epidemiological signal. We have simply not generalized the principle.

**Conversational but undocumented.** Perhaps the largest category of health-relevant communication is the unstructured human conversation that never enters any record: a grandmother's advice, a community healer's counsel, a patient's illness narrative told to family. In oral cultures, these are not supplementary to clinical care. They *are* clinical care. An estimated 40% of the world's languages have no writing system. For the communities that speak them, health knowledge is transmitted entirely through communicative forms that clinical AI has no mechanism to receive.

We propose the concept of **communicative wholeness** as a counterpart to "whole-person care." Just as whole-person medicine insists that health cannot be reduced to organ systems, communicative wholeness insists that clinical communication cannot be reduced to text. And just as the reductive biomedical model produces systematic blind spots in care, the textual presumption in clinical AI produces systematic *deafness* — a structural inability to hear the very communicative acts through which much of the world's healing actually occurs.

This is not merely a theoretical concern. It has direct consequences. When a clinical AI system is deployed in a community where health knowledge is transmitted through oral narrative, song, or environmental reading, the system does not encounter a "low-resource language" problem. It encounters a *category error*: it is listening for text in a world that heals through other means.

---

## 3. Research Program

We propose a 12-month program structured around three interlocking components. Its central methodological innovation is that the primary research instrument is not a survey, a corpus, or a dataset — it is **the convening itself**. We bring to MIT the people who speak in the languages that clinical AI cannot hear — healers, musicians, visual artists, drum practitioners, community health workers, storytellers — and place them in structured dialogue with linguists, AI researchers, and clinicians. The encounter between these ways of communicating *is* the data. The January 15 event, supported by the AMA, demonstrated the extraordinary generativity of this method. This project scales and formalizes it.

### Component A: The Communicative Health Taxonomy (Months 1–6)
*Lead: Per Urlaub, with Leo Celi*

Drawing on the linguistic and semiotic literature, and in dialogue with practitioners identified through MIT Critical Data's global network (spanning 30+ countries), we develop a formal taxonomy of health-relevant communicative acts that extends beyond text. This is an analytical framework, not an ethnography. It asks: across all the ways humans (and the living world) communicate about health, what categories exist, and which ones does clinical AI currently capture?

Categories under investigation include:
- **Textual** (structured clinical documentation — the current foundation of clinical AI)
- **Prosodic and paralinguistic** (tone, rhythm, silence, vocal quality — what text strips from speech)
- **Somatic and gestural** (body posture, movement, touch — what video might capture but records cannot)
- **Musical and rhythmic** (healing through sound, drum, chant, melody — communicative acts irreducible to words)
- **Visual and spatial** (drawing, sand painting, spatial arrangement — healing as image and form)
- **Environmental and ecological** (weather, animal behavior, seasonal pattern — the communicative field between organisms and their surroundings)
- **Luminous and atmospheric** (light quality, time of day, thermal sensation — communicative dimensions that some healing traditions attend to explicitly)
- **Oral-narrative but undocumented** (the grandmother's story, the community conversation, the healer's counsel — health communication that is structured, consequential, and invisible to records)

The output is a **Communicative Health Taxonomy** that maps these categories, identifies which are represented in current clinical AI architectures (very few), and provides the conceptual scaffolding for what a communicatively whole clinical AI would need to attend to.

### Component B: Measuring What Text Leaves Out (Months 4–9)
*Lead: Leo Celi, with Per Urlaub*

Using the MIMIC database and PhysioNet infrastructure, combined with multimodal clinical encounter recordings where ethically available, we quantify the epistemic cost of the textual presumption:

- Systematic comparison of clinical information available in full multimodal encounter recordings versus the corresponding medical record text — measuring the information loss at the documentation boundary
- Analysis of paralinguistic and contextual features that carry diagnostic information but are absent from clinical AI training data
- Case studies of clinical scenarios where text-based AI fails precisely because the relevant signal is non-textual (e.g., mental health assessment, pain evaluation, pediatric care, palliative and end-of-life contexts where presence and silence carry immense communicative weight)
- Connection to care phenotype research: do the non-textual communicative dimensions of care differ systematically across patient populations, and does this explain disparities that text-based AI cannot detect?

This component transforms "clinical AI misses important signals" from an assertion into a demonstrated, quantified finding.

### Component C: The Convening — Bringing the Unheard Languages to MIT (Months 8–12)
*Lead: Joint*

The centerpiece of this project is a landmark convening at MIT: **"The Languages of Healing."** Building on the January 15 event, we bring to campus people from around the world who communicate in the languages that clinical AI cannot hear — not as subjects of study, but as co-investigators:

- **Musicians and sound healers** — practitioners who work with rhythm, tone, and melody as therapeutic modalities, from diverse traditions
- **Visual artists and practitioners** — people for whom drawing, painting, or spatial arrangement is a communicative act connected to health and wholeness
- **Indigenous knowledge keepers** — including practitioners who use the drum, chant, and environmental reading as diagnostic and healing tools
- **Practitioners of light and atmosphere** — artists and healers who work with luminous, thermal, and atmospheric qualities as communicative media
- **Community health workers and oral tradition carriers** — from MIT Critical Data's global network, people whose health communication occurs entirely outside written systems
- **Clinicians, linguists, and AI researchers** — to listen, to be challenged, and to co-develop the framework

The convening is not a conference with presentations. It is a structured research encounter: each communicative tradition *demonstrates* its practice, and the interdisciplinary team works together to analyze what is being communicated, through what channels, and what would be required for any AI system to attend to it. The proceedings are recorded, analyzed, and synthesized into:

1. **A major theoretical framework paper** for a high-impact interdisciplinary journal, articulating the expanded semiotics of health and its implications for clinical AI design
2. **Design principles for communicatively whole clinical AI** — an architectural agenda specifying what data modalities, semiotic frameworks, and epistemological commitments would be required
3. **A research agenda and follow-on proposal** (targeting NIH, NSF, or Wellcome Trust) for a larger program that builds and tests prototype systems informed by the framework

---

## 4. Why This Team, Why MIT, Why Now

**Per Urlaub** (SHASS PI, Global Languages) brings expertise in applied linguistics, cross-cultural communication, and the theory of how meaning is constructed across linguistic and cultural boundaries. Critically, linguistics is not a service discipline in this project — it provides the core theoretical apparatus. The question *what is language?* is the question that drives the entire program. Only a linguist can pose it with the necessary rigor and depth. Urlaub's work on multiliteracies and meaning-making across semiotic systems positions him uniquely to develop the Communicative Health Taxonomy that is this project's foundational output.

**Leo Anthony Celi** (Co-PI, IMES / MIT Critical Data) brings the clinical AI infrastructure — the MIMIC database, PhysioNet, and a global network of community partnerships in over 30 countries — along with deep expertise in healthcare AI equity. His BODHI framework (Bridging, Open, Discerning, Humble, Inquiring) provides the ethical architecture for this work. His ongoing DOJO initiative (Distributed Open Justice Oversight — community-operated adversarial testing for healthcare AI, which evaluates models through community-contributed agents trained on diverse ethical and cultural frameworks) offers a concrete platform for testing whether expanded communicative inputs improve clinical AI performance and fairness. Celi's network, which convened approximately 100 participants from diverse backgrounds at MIT on January 15, 2026 with AMA support, provides the global reach needed to bring practitioners of unheard healing languages to the convening.

**Why this collaboration is structurally necessary:** A computer scientist would optimize existing text-based systems. A public health researcher would document disparities. An anthropologist would describe healing practices. Only a linguist can ask the foundational question — *what counts as clinical communication?* — with the theoretical precision to produce a formal framework. And only a clinical AI researcher embedded in global health partnerships can connect that framework to the systems being deployed worldwide, and convene the global community of practitioners whose communicative practices this project centers. Neither could do this work alone. The SHASS contribution is not peripheral to the technical work — it *is* the core intellectual contribution, redefining the category that clinical AI takes as given.

**Why now:** Three developments have converged to create a unique window:

- The recognition of artificial general intelligence (Chen et al., 2026) has made the substrate-independence of intelligence undeniable, opening conceptual space for recognizing the medium-independence of health communication
- The maturation of One Health, planetary health, and network medicine has made the relational nature of health undeniable — and yet clinical AI has not caught up
- The accelerating global deployment of clinical AI into contexts where healing is not text-based has made the consequences of the textual presumption urgent and concrete
- The January 15, 2026 convening at MIT demonstrated both the demand for and the feasibility of bringing these conversations into rigorous interdisciplinary dialogue

This project is not ahead of its time. It is exactly on time.

---

## 5. Timeline, Budget, and Expected Impact

### Timeline

| Period | Activity | Lead |
|---|---|---|
| Months 1–3 | Communicative Health Taxonomy development; literature synthesis; identification and outreach to global convening participants | Joint |
| Months 4–7 | MIMIC/PhysioNet analysis of communicative truncation; taxonomy refinement through remote dialogues with practitioners | Leo Celi / Per Urlaub |
| Months 7–8 | Convening design and preparation; pre-convening dialogues with participants | Joint |
| Month 9 | **MIT Convening: "The Languages of Healing"** — 3-day structured research encounter | Joint |
| Months 10–12 | Framework synthesis; paper drafting; design principles; follow-on proposal development | Joint |

### Budget: $175,000 (direct costs)

| Category | Amount | Notes |
|---|---|---|
| Postdoctoral researcher (linguistic anthropology / health semiotics) | $60,000 | 50% FTE, joint supervision across both labs |
| Graduate research assistant (SHASS — semiotic analysis) | $20,000 | |
| **Global Convening: "The Languages of Healing"** | **$45,000** | Travel and accommodation for 15–20 international participants (musicians, indigenous practitioners, healers, artists, community health workers); honoraria and community compensation; 3-day structured encounter at MIT |
| Pre-convening remote dialogues and participant engagement | $10,000 | Video recording, translation, facilitation for preparatory sessions |
| Multimodal recording and analysis | $10,000 | Professional documentation of convening (audio, video, spatial) for subsequent semiotic analysis |
| MIMIC/PhysioNet computational analysis | $5,000 | Computing resources |
| Translation, interpretation, and accessibility | $10,000 | Ensuring the convening itself models communicative wholeness |
| Publication (open access) and dissemination | $5,000 | |
| PI summer salary support | $10,000 | |

**Supplemental requests:** 2 UROPs (one in linguistics/semiotics, one in CS/AI); part-time use of Building 16 collaborative space for the convening and for ongoing work.

### Expected Impact

**Intellectual:** A new theoretical framework — the expanded semiotics of health — that redefines the communicative foundations of clinical AI. We anticipate a publication in a high-impact interdisciplinary venue and the opening of a research direction at the intersection of linguistics, healthcare AI, and indigenous knowledge systems that does not currently exist.

**Practical:** Actionable design principles for clinical AI developers, arguing that text-based systems are communicatively incomplete by construction. A roadmap for incorporating multimodal, multicultural, and ecologically embedded communicative signals into health AI.

**For global health equity:** This framework directly serves communities whose healing practices are oral, somatic, musical, or ecological — communities that current clinical AI is structurally incapable of serving, regardless of how many languages it speaks.

**Transformative potential:** This project positions MIT at the vanguard of a paradigm shift in clinical AI. The field currently asks: *how do we make AI speak more languages?* We ask: *how do we make AI listen to the languages of healing that humans have always spoken — and that the living world speaks still?* The former is an engineering problem. The latter is a humanistic one. It requires SHASS at its center.

---

### Selected References

Chen, E.K., Belkin, M., Bergen, L. & Danks, D. "Does AI already have human-level intelligence? The evidence is clear." *Nature* 650, 36–40 (2026).

Kohn, E. *How Forests Think: Toward an Anthropology Beyond the Human.* University of California Press (2013).

Sebeok, T.A. *Signs: An Introduction to Semiotics.* University of Toronto Press (2001).

Celi, L.A. et al. "Sources of bias in artificial intelligence that perpetuate healthcare disparities." *PLOS Digital Health* 1(3), e0000022 (2022).

World Health Organization. *One Health Joint Plan of Action 2022–2026.* WHO (2022).

Metzl, J.M. & Hansen, H. "Structural competency: Theorizing a new medical engagement with stigma and inequality." *Social Science & Medicine* 103, 126–133 (2014).

Barbour, W. & Schlesinger, C. "Who's the boss? Post-colonialism, ecological research and conservation management on Australian Indigenous lands." *Ecological Management & Restoration* 13(1), 36–41 (2012).
