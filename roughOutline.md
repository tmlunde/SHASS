Core Proposal: "Language Justice in Clinical AI: Building Equitable Systems Across the World's Medical Lexicons"

*Central thesis*: Clinical AI systems are fundamentally linguistic artifacts that encode medical epistemologies through language structures. Current systems are built almost exclusively on English clinical language, creating both technical failures and epistemic violence when deployed globally. This project develops frameworks for multilingual clinical AI that respects linguistic diversity as a form of epistemic diversity.

---

## *Why This Partnership Is Compelling*

*The natural bridge*: 
- You bring: Clinical AI ethics, global health equity, community-partnered research, care delivery patterns
- Per brings: Linguistic theory, language documentation, cross-linguistic semantics, potentially endangered/minority language expertise
- Together: A genuinely novel approach to AI fairness that centers language as fundamental to epistemic justice

*Interdisciplinarity reviewers can see: Neither computer scientists alone, nor ethicists alone, nor linguists alone could tackle this. The collaboration is **structurally necessary*.

---

## *Three Sub-Framings (Choose One or Combine)*

### *Option A: "Medical Uncertainty Across Languages"*

*Research question*: How do different languages encode medical uncertainty, and what happens when AI systems trained on English uncertainty markers are deployed in other linguistic contexts?

*SHASS core (joint)*:
- Cross-linguistic analysis of uncertainty expression in clinical documentation (Per's expertise)
- Ethnographic study of how clinicians in different language communities express doubt, confidence, epistemic limits (your methodology)
- Philosophy of language meets philosophy of medicine
- Links directly to THOMAS/BODHI epistemic virtues framework

*Engineering component* (Co-PI or collaborator):
- NLP analysis of uncertainty markers across languages in clinical text
- Development of multilingual clinical language models
- Testing whether uncertainty calibration differs by language
- Building language-aware explanation systems

*Concrete deliverables*:
- Corpus analysis of uncertainty expression in clinical notes from 3-5 languages (English + languages from your Uganda/Brazil/Korea partnerships)
- Prototype multilingual uncertainty detection system
- Framework for "linguistic epistemic humility" in clinical AI
- Guidelines for language-inclusive clinical AI development

*Unique strength*: Connects your epistemic virtues work to concrete linguistic analysis. Per's theoretical expertise makes the philosophy operational.

---

### *Option B: "Care Phenotypes and Linguistic Markers of Care Delivery"*

*Research question*: Do linguistic patterns in clinical documentation reveal care delivery inequities that demographic data miss? Can language be a proxy for care phenotypes?

*SHASS core (joint)*:
- Sociolinguistic analysis of how clinicians write differently about different patients (Per)
- Your care phenotypes framework applied through linguistic lens
- Critical discourse analysis of medical language and power
- Connection to your work on bias beyond demographics

*Engineering component*:
- NLP tools to detect linguistic markers of care quality
- Analysis of MIMIC data for language-based care patterns
- Cross-linguistic validation in your international sites
- Development of language-aware fairness metrics

*Concrete deliverables*:
- Linguistic care phenotype taxonomy
- Computational tools for detecting linguistic bias in clinical notes
- Validation across English and at least 2 other languages
- Training materials for clinicians on equitable clinical documentation

*Unique strength*: Makes care phenotypes concrete and measurable through language. Addresses documentation bias, which is huge in clinical AI.

---

### *Option C: "Indigenous Medical Knowledge and Linguistic Ontologies in AI"*

*Research question*: How can clinical AI systems incorporate non-Western medical ontologies that are encoded in non-dominant languages?

*SHASS core (joint)*:
- Language documentation methods applied to medical terminology (Per)
- Your community-partnered approaches and indigenous knowledge work
- Linguistic anthropology of medical systems
- Decolonial AI theory through linguistic lens

*Engineering component*:
- Multilingual medical knowledge graphs
- Ontology alignment across medical traditions
- Low-resource language NLP for clinical contexts
- Community-in-the-loop AI development

*Concrete deliverables*:
- Case study with one indigenous/minority language medical system (potentially through Uganda partnerships)
- Framework for linguistically pluralistic medical AI
- Prototype system that can reason across medical ontologies
- Workshop bringing together indigenous health practitioners, linguists, and AI developers

*Unique strength*: Most radical and distinctive. Directly addresses epistemic justice. Could be transformative but also highest risk for one-year timeline.

---

## *My Recommended Hybrid: "Linguistic Equity in Clinical AI: From Uncertainty to Care"*

Combine elements of A and B for maximum impact and feasibility:

### *Phase 1: Foundations (Months 1-4)*
- Cross-linguistic corpus development: Collect clinical notes in English + 2-3 languages from your international partnerships
- Linguistic analysis: Per leads analysis of uncertainty markers and care-related language patterns
- You lead: Parallel ethnographic work on clinical communication practices

### *Phase 2: Computational Analysis (Months 5-8)*
- NLP analysis of linguistic markers in clinical text
- Identify language-based care phenotypes
- Test for linguistic bias in existing clinical AI systems
- Engineering collaborator (or UROP team) builds analytical tools

### *Phase 3: Framework Development (Months 9-12)*
- Synthesize findings into "Linguistic Justice Framework for Clinical AI"
- Develop design guidelines for multilingual clinical AI
- Create educational materials
- Host workshop/datathon bringing linguists and AI developers together

---

## *Why This Works for SHASS+ Connectivity Fund*

*Intellectual merit*:
- Completely novel intersection: clinical AI ethics × linguistic theory × global health
- Advances both AI fairness scholarship AND sociolinguistics
- Original theoretical contribution: language as vector of both bias AND epistemic diversity

*Depth of collaboration*:
- SHASS elements absolutely central: linguistic theory, ethnography, philosophy of language/medicine
- Requires Per's expertise throughout - not just "consulting"
- Your community partnerships provide linguistic diversity necessary for research
- Engineering needed but in service of SHASS questions

*Potential impact*:
- Clinical AI is global - this work has immediate real-world relevance
- Connects to broader AI ethics debates about cultural adaptation
- Opens new research directions in both NLP and medical AI
- Supports your medical education reimagining work (Jan 15 event)

*Feasibility*:
- You already have international partnerships and data access
- Per brings established linguistic methods
- Can scope to achievable deliverables in one year
- Planning grant option if you want to start smaller

---

## *Budget Narrative ($120K-$180K range)*

*Personnel*:
- Postdoc with computational linguistics background (40-50% distributed across both labs): $50-60K
- Graduate student RA (SHASS - qualitative/ethnographic work): $20-25K
- 2 UROPs (one linguistics, one CS/NLP): Supplemental request

*Research expenses*:
- International data collection/partnership support (Uganda, Brazil, or Korea): $15-20K
- Transcription/translation services: $10-15K
- Corpus development and annotation: $10K
- Computing resources for NLP analysis: $5K

*Convening*:
- Workshop bringing linguists + AI developers + clinicians together: $15-20K
- Travel for team coordination: $5-10K

*Other*:
- Part-time space in Building 16 (supplemental request)
- Publication/dissemination: $5K

---

## *Positioning Statements for Proposal*

*Opening hook*: 
"A clinical AI system trained on English medical records that expresses 'moderate confidence' may fail catastrophically when deployed in contexts where clinicians express uncertainty differently - not because the medicine is different, but because the language is. Yet current approaches to clinical AI fairness ignore language entirely, treating it as a neutral medium rather than a fundamental carrier of medical epistemology and care practices."

*On interdisciplinarity*: 
"This project requires deep integration of linguistic theory and clinical AI ethics. Neither computer science alone, nor linguistics alone, nor medical ethics alone can address how language structures both encode and create inequities in AI systems. We need Per's expertise in cross-linguistic semantics to identify what patterns matter, and my expertise in clinical care delivery to understand what those patterns mean for patient outcomes."

*On SHASS centrality*: 
"While the project includes computational analysis, the core questions are humanistic: How does language shape medical knowing? Whose ways of speaking about illness are encoded in AI systems? What epistemic traditions are erased when we assume linguistic universality in clinical AI? The technical work serves to make these SHASS questions empirically answerable and practically actionable."

---

## *Risk Mitigation*

*Language access*: You already have partnerships in non-English contexts. Start with languages where you have existing collaborations (Portuguese in Brazil, Luganda in Uganda, Korean).

*Technical complexity*: Scope NLP work appropriately - you're not building production systems, you're doing critical analysis and proof-of-concept.

*IRB/data access*: MIMIC you already manage; international data may need new agreements but you have relationships.

*Timeline*: Focus Phase 1 on corpus development and linguistic analysis where Per can lead. This creates immediate productivity while engineering components ramp up.

---

## *Connection to Your Broader Agenda*

- *January 15 event*: Language justice in medical education is perfect tie-in
- *THOMAS/BODHI*: Linguistic diversity as epistemic diversity
- *Care phenotypes*: Language as measurable indicator of care delivery
- *AI plasticity*: How monolingual AI development constrains medical thinking
- *Community partnership*: Centers language communities as knowledge holdersCore Proposal: "Language Justice in Clinical AI: Building Equitable Systems Across the World's Medical Lexicons"

*Central thesis*: Clinical AI systems are fundamentally linguistic artifacts that encode medical epistemologies through language structures. Current systems are built almost exclusively on English clinical language, creating both technical failures and epistemic violence when deployed globally. This project develops frameworks for multilingual clinical AI that respects linguistic diversity as a form of epistemic diversity.

---

## *Why This Partnership Is Compelling*

*The natural bridge*: 
- You bring: Clinical AI ethics, global health equity, community-partnered research, care delivery patterns
- Per brings: Linguistic theory, language documentation, cross-linguistic semantics, potentially endangered/minority language expertise
- Together: A genuinely novel approach to AI fairness that centers language as fundamental to epistemic justice

*Interdisciplinarity reviewers can see: Neither computer scientists alone, nor ethicists alone, nor linguists alone could tackle this. The collaboration is **structurally necessary*.

---

## *Three Sub-Framings (Choose One or Combine)*

### *Option A: "Medical Uncertainty Across Languages"*

*Research question*: How do different languages encode medical uncertainty, and what happens when AI systems trained on English uncertainty markers are deployed in other linguistic contexts?

*SHASS core (joint)*:
- Cross-linguistic analysis of uncertainty expression in clinical documentation (Per's expertise)
- Ethnographic study of how clinicians in different language communities express doubt, confidence, epistemic limits (your methodology)
- Philosophy of language meets philosophy of medicine
- Links directly to THOMAS/BODHI epistemic virtues framework

*Engineering component* (Co-PI or collaborator):
- NLP analysis of uncertainty markers across languages in clinical text
- Development of multilingual clinical language models
- Testing whether uncertainty calibration differs by language
- Building language-aware explanation systems

*Concrete deliverables*:
- Corpus analysis of uncertainty expression in clinical notes from 3-5 languages (English + languages from your Uganda/Brazil/Korea partnerships)
- Prototype multilingual uncertainty detection system
- Framework for "linguistic epistemic humility" in clinical AI
- Guidelines for language-inclusive clinical AI development

*Unique strength*: Connects your epistemic virtues work to concrete linguistic analysis. Per's theoretical expertise makes the philosophy operational.

---

### *Option B: "Care Phenotypes and Linguistic Markers of Care Delivery"*

*Research question*: Do linguistic patterns in clinical documentation reveal care delivery inequities that demographic data miss? Can language be a proxy for care phenotypes?

*SHASS core (joint)*:
- Sociolinguistic analysis of how clinicians write differently about different patients (Per)
- Your care phenotypes framework applied through linguistic lens
- Critical discourse analysis of medical language and power
- Connection to your work on bias beyond demographics

*Engineering component*:
- NLP tools to detect linguistic markers of care quality
- Analysis of MIMIC data for language-based care patterns
- Cross-linguistic validation in your international sites
- Development of language-aware fairness metrics

*Concrete deliverables*:
- Linguistic care phenotype taxonomy
- Computational tools for detecting linguistic bias in clinical notes
- Validation across English and at least 2 other languages
- Training materials for clinicians on equitable clinical documentation

*Unique strength*: Makes care phenotypes concrete and measurable through language. Addresses documentation bias, which is huge in clinical AI.

---

### *Option C: "Indigenous Medical Knowledge and Linguistic Ontologies in AI"*

*Research question*: How can clinical AI systems incorporate non-Western medical ontologies that are encoded in non-dominant languages?

*SHASS core (joint)*:
- Language documentation methods applied to medical terminology (Per)
- Your community-partnered approaches and indigenous knowledge work
- Linguistic anthropology of medical systems
- Decolonial AI theory through linguistic lens

*Engineering component*:
- Multilingual medical knowledge graphs
- Ontology alignment across medical traditions
- Low-resource language NLP for clinical contexts
- Community-in-the-loop AI development

*Concrete deliverables*:
- Case study with one indigenous/minority language medical system (potentially through Uganda partnerships)
- Framework for linguistically pluralistic medical AI
- Prototype system that can reason across medical ontologies
- Workshop bringing together indigenous health practitioners, linguists, and AI developers

*Unique strength*: Most radical and distinctive. Directly addresses epistemic justice. Could be transformative but also highest risk for one-year timeline.

---

## *My Recommended Hybrid: "Linguistic Equity in Clinical AI: From Uncertainty to Care"*

Combine elements of A and B for maximum impact and feasibility:

### *Phase 1: Foundations (Months 1-4)*
- Cross-linguistic corpus development: Collect clinical notes in English + 2-3 languages from your international partnerships
- Linguistic analysis: Per leads analysis of uncertainty markers and care-related language patterns
- You lead: Parallel ethnographic work on clinical communication practices

### *Phase 2: Computational Analysis (Months 5-8)*
- NLP analysis of linguistic markers in clinical text
- Identify language-based care phenotypes
- Test for linguistic bias in existing clinical AI systems
- Engineering collaborator (or UROP team) builds analytical tools

### *Phase 3: Framework Development (Months 9-12)*
- Synthesize findings into "Linguistic Justice Framework for Clinical AI"
- Develop design guidelines for multilingual clinical AI
- Create educational materials
- Host workshop/datathon bringing linguists and AI developers together

---

## *Why This Works for SHASS+ Connectivity Fund*

*Intellectual merit*:
- Completely novel intersection: clinical AI ethics × linguistic theory × global health
- Advances both AI fairness scholarship AND sociolinguistics
- Original theoretical contribution: language as vector of both bias AND epistemic diversity

*Depth of collaboration*:
- SHASS elements absolutely central: linguistic theory, ethnography, philosophy of language/medicine
- Requires Per's expertise throughout - not just "consulting"
- Your community partnerships provide linguistic diversity necessary for research
- Engineering needed but in service of SHASS questions

*Potential impact*:
- Clinical AI is global - this work has immediate real-world relevance
- Connects to broader AI ethics debates about cultural adaptation
- Opens new research directions in both NLP and medical AI
- Supports your medical education reimagining work (Jan 15 event)

*Feasibility*:
- You already have international partnerships and data access
- Per brings established linguistic methods
- Can scope to achievable deliverables in one year
- Planning grant option if you want to start smaller

---

## *Budget Narrative ($120K-$180K range)*

*Personnel*:
- Postdoc with computational linguistics background (40-50% distributed across both labs): $50-60K
- Graduate student RA (SHASS - qualitative/ethnographic work): $20-25K
- 2 UROPs (one linguistics, one CS/NLP): Supplemental request

*Research expenses*:
- International data collection/partnership support (Uganda, Brazil, or Korea): $15-20K
- Transcription/translation services: $10-15K
- Corpus development and annotation: $10K
- Computing resources for NLP analysis: $5K

*Convening*:
- Workshop bringing linguists + AI developers + clinicians together: $15-20K
- Travel for team coordination: $5-10K

*Other*:
- Part-time space in Building 16 (supplemental request)
- Publication/dissemination: $5K

---

## *Positioning Statements for Proposal*

*Opening hook*: 
"A clinical AI system trained on English medical records that expresses 'moderate confidence' may fail catastrophically when deployed in contexts where clinicians express uncertainty differently - not because the medicine is different, but because the language is. Yet current approaches to clinical AI fairness ignore language entirely, treating it as a neutral medium rather than a fundamental carrier of medical epistemology and care practices."

*On interdisciplinarity*: 
"This project requires deep integration of linguistic theory and clinical AI ethics. Neither computer science alone, nor linguistics alone, nor medical ethics alone can address how language structures both encode and create inequities in AI systems. We need Per's expertise in cross-linguistic semantics to identify what patterns matter, and my expertise in clinical care delivery to understand what those patterns mean for patient outcomes."

*On SHASS centrality*: 
"While the project includes computational analysis, the core questions are humanistic: How does language shape medical knowing? Whose ways of speaking about illness are encoded in AI systems? What epistemic traditions are erased when we assume linguistic universality in clinical AI? The technical work serves to make these SHASS questions empirically answerable and practically actionable."

---

## *Risk Mitigation*

*Language access*: You already have partnerships in non-English contexts. Start with languages where you have existing collaborations (Portuguese in Brazil, Luganda in Uganda, Korean).

*Technical complexity*: Scope NLP work appropriately - you're not building production systems, you're doing critical analysis and proof-of-concept.

*IRB/data access*: MIMIC you already manage; international data may need new agreements but you have relationships.

*Timeline*: Focus Phase 1 on corpus development and linguistic analysis where Per can lead. This creates immediate productivity while engineering components ramp up.

---

## *Connection to Your Broader Agenda*

- *January 15 event*: Language justice in medical education is perfect tie-in
- *THOMAS/BODHI*: Linguistic diversity as epistemic diversity
- *Care phenotypes*: Language as measurable indicator of care delivery
- *AI plasticity*: How monolingual AI development constrains medical thinking
- *Community partnership*: Centers language communities as knowledge holders
